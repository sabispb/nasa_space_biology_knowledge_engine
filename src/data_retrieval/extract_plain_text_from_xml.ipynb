{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ccc85-b084-423b-a2fc-40b942612698",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154ee1e-2306-4cff-abaa-7259e5e8961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import html\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1463930-404a-4da5-aaf6-615d91ac6c9a",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bbb5b-283a-4b29-9b9e-06408a1e7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"data/SB_publication_PMC_with_xml.parquet\"\n",
    "OUTPUT_FILE = \"data/SB_publication_PMC_texts.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7904c5-4381-491b-b65b-c745264a12ae",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3fca3-ea96-442c-a62e-f4fe540f2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_FILE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75e3fc-90cc-4191-b0db-81bd11cd25b4",
   "metadata": {},
   "source": [
    "# Extract abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf0fe7-44fc-4f1e-ab36-4089e916e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract_text(\n",
    "    xml_bytes: bytes,\n",
    "    include_translated: bool = True,\n",
    "    join_with: str = \"\\n\\n\"\n",
    ") -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts abstract(s) from a JATS/PMC XML file as plain text.\n",
    "\n",
    "    - Includes <abstract> and optionally <trans-abstract>.\n",
    "    - Keeps real <title> tags (UPPERCASE), removes synthetic \"ABSTRACT\" headers.\n",
    "    - Strips all leading/trailing newlines and spaces.\n",
    "    - Ignores style tags (<italic>, <bold>, etc.) but keeps their text content.\n",
    "    - Normalizes whitespace and decodes HTML entities.\n",
    "\n",
    "    Args:\n",
    "        xml_bytes (bytes): The XML content.\n",
    "        include_translated (bool): Whether to include translated abstracts.\n",
    "        join_with (str): Separator between multiple abstracts.\n",
    "\n",
    "    Returns:\n",
    "        str | None: Clean plain-text abstract(s), or None if not found.\n",
    "    \"\"\"\n",
    "    # Handle weird serialized byte literals like b'<?xml ...'\n",
    "    if isinstance(xml_bytes, (bytes, bytearray)):\n",
    "        s = xml_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
    "        if (s.startswith(\"b'\") or s.startswith('b\"')) and s.endswith((\"'\", '\"')):\n",
    "            try:\n",
    "                xml_bytes = ast.literal_eval(s)\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            xml_bytes = s\n",
    "    if isinstance(xml_bytes, str):\n",
    "        xml_str = xml_bytes\n",
    "    else:\n",
    "        xml_str = xml_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    root = ET.fromstring(xml_str)\n",
    "\n",
    "    def local(tag: str) -> str:\n",
    "        return tag.split(\"}\")[-1] if \"}\" in tag else tag\n",
    "\n",
    "    def norm_text(t: str) -> str:\n",
    "        \"\"\"Normalize whitespace and decode HTML entities.\"\"\"\n",
    "        t = html.unescape(t or \"\")\n",
    "        return \" \".join(t.split())\n",
    "\n",
    "    def get_all_text(el: Optional[ET.Element]) -> str:\n",
    "        \"\"\"Flatten element text (ignore tags, keep text).\"\"\"\n",
    "        if el is None:\n",
    "            return \"\"\n",
    "        return norm_text(\"\".join(el.itertext()))\n",
    "\n",
    "    # Collect <abstract> and optionally <trans-abstract>\n",
    "    candidates: List[ET.Element] = []\n",
    "    for el in root.iter():\n",
    "        lt = local(el.tag)\n",
    "        if lt == \"abstract\" or (include_translated and lt == \"trans-abstract\"):\n",
    "            candidates.append(el)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    out_chunks: List[str] = []\n",
    "\n",
    "    for abs_el in candidates:\n",
    "        # Real title of the abstract (if any)\n",
    "        title_el = abs_el.find(\"./title\")\n",
    "        if title_el is not None and get_all_text(title_el):\n",
    "            out_chunks.append(get_all_text(title_el).upper())\n",
    "\n",
    "        # Handle structured abstracts (<sec>)\n",
    "        secs = [s for s in abs_el.findall(\"./sec\")]\n",
    "        if secs:\n",
    "            for sec in secs:\n",
    "                sec_title = get_all_text(sec.find(\"./title\"))\n",
    "                if sec_title:\n",
    "                    out_chunks.append(sec_title.upper())\n",
    "                for p in sec.findall(\".//p\"):\n",
    "                    txt = get_all_text(p)\n",
    "                    if txt:\n",
    "                        out_chunks.append(txt)\n",
    "        else:\n",
    "            # Simple abstract (just <p> or text)\n",
    "            ps = abs_el.findall(\"./p\")\n",
    "            if ps:\n",
    "                for p in ps:\n",
    "                    txt = get_all_text(p)\n",
    "                    if txt:\n",
    "                        out_chunks.append(txt)\n",
    "            else:\n",
    "                txt = get_all_text(abs_el)\n",
    "                if title_el is not None:\n",
    "                    title_txt = get_all_text(title_el)\n",
    "                    if txt.startswith(title_txt):\n",
    "                        txt = txt[len(title_txt):].lstrip()\n",
    "                if txt:\n",
    "                    out_chunks.append(txt)\n",
    "\n",
    "    # Clean up and join\n",
    "    cleaned = [chunk.strip() for chunk in out_chunks if chunk.strip()]\n",
    "    text = join_with.join(cleaned)\n",
    "\n",
    "    # Remove any leading \"ABSTRACT\" (or \"ABSTRACT 1\") and stray newlines/spaces\n",
    "    text = re.sub(r\"^(ABSTRACT\\s*\\d*\\s*)\", \"\", text, flags=re.IGNORECASE).lstrip(\"\\n\").strip()\n",
    "\n",
    "    return text if text else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d49c5a-66af-4e4f-8e3b-1e40413c8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"abstract\"] = df[\"xml\"].apply(get_abstract_text)\n",
    "df[\"abstract\"] = df[\"abstract\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9228d5-00a4-412b-ba6f-f21c46c444da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"len\"] = df[\"abstract\"].apply(len)\n",
    "df[\"len\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c29582-f399-44f8-aca3-5a6c4b29a4e2",
   "metadata": {},
   "source": [
    "# Extract plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749d3c7-826f-4483-b652-0b9dfa2dba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "from typing import List, Optional, Iterable\n",
    "import ast\n",
    "import html\n",
    "\n",
    "def get_plain_body_text(xml_bytes: bytes, fallback_to_abstract: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Extreu el cos de l'article com a text pla.\n",
    "    - Títols de secció en MAJÚSCULES.\n",
    "    - Es descarten etiquetes d'estil (italic, bold, etc.) però es conserva el text.\n",
    "    - Normalitza espais en paràgrafs.\n",
    "    - Salta figures/taules/ref-list.\n",
    "    - Si no hi ha <body>, opcionalment fa fallback a <abstract> / <trans-abstract>.\n",
    "\n",
    "    Args:\n",
    "        xml_bytes: XML de l'article (bytes). Admet bytes amb prefix b'...' serialitzat.\n",
    "        fallback_to_abstract: Si True i no hi ha <body>, retorna el(s) abstract(s).\n",
    "\n",
    "    Returns:\n",
    "        str: Text pla amb encapçalaments i paràgrafs. Pot retornar \"\" si no troba res.\n",
    "    \"\"\"\n",
    "    # Alguns dumps arriben com a str dins d'uns bytes: b'<?xml ...</pmc-articleset>'\n",
    "    # Intentem \"desempaquetar-ho\" de forma segura.\n",
    "    if isinstance(xml_bytes, (bytes, bytearray)):\n",
    "        try:\n",
    "            s = xml_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
    "            if (s.startswith(\"b'\") or s.startswith('b\"')) and s.endswith((\"'\", '\"')):\n",
    "                xml_bytes = ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Parse\n",
    "    if isinstance(xml_bytes, str):\n",
    "        xml_bytes = xml_bytes.encode(\"utf-8\")\n",
    "    root = ET.fromstring(xml_bytes)\n",
    "\n",
    "    def local(tag: str) -> str:\n",
    "        return tag.split(\"}\")[-1] if \"}\" in tag else tag\n",
    "\n",
    "    # Utils\n",
    "    def _text(el: Optional[ET.Element]) -> str:\n",
    "        if el is None:\n",
    "            return \"\"\n",
    "        raw = \"\".join(el.itertext())\n",
    "        raw = html.unescape(raw)\n",
    "        return \" \".join(raw.split())\n",
    "\n",
    "    def add_blank_line(lines: List[str]):\n",
    "        if lines and lines[-1] != \"\":\n",
    "            lines.append(\"\")\n",
    "\n",
    "    # ----------- BODY PATH -----------\n",
    "    body = None\n",
    "    # A vegades el body és directe; altres cops hi ha namespaces\n",
    "    for cand in root.iter():\n",
    "        if local(cand.tag) == \"body\":\n",
    "            body = cand\n",
    "            break\n",
    "\n",
    "    lines: List[str] = []\n",
    "\n",
    "    SKIP_TAGS = {\n",
    "        \"fig\", \"fig-group\", \"table\", \"table-wrap\", \"table-wrap-foot\",\n",
    "        \"supplementary-material\", \"ref-list\", \"media\", \"graphic\"\n",
    "    }\n",
    "\n",
    "    def handle_block(block: ET.Element):\n",
    "        btag = local(block.tag)\n",
    "        if btag == \"list\":\n",
    "            for li in block.findall(\"./*\"):\n",
    "                if local(li.tag) != \"list-item\":\n",
    "                    continue\n",
    "                label = li.find(\"./label\")\n",
    "                label_text = _text(label)\n",
    "                p_children = [c for c in li.findall(\"./*\") if local(c.tag) == \"p\"]\n",
    "                if p_children:\n",
    "                    for p in p_children:\n",
    "                        t = _text(p)\n",
    "                        if t:\n",
    "                            lines.append(f\"{label_text} {t}\".strip() if label_text else t)\n",
    "                    lines.append(\"\")\n",
    "                else:\n",
    "                    t = _text(li)\n",
    "                    if t:\n",
    "                        lines.append(f\"{label_text} {t}\".strip() if label_text else t)\n",
    "                        lines.append(\"\")\n",
    "        elif btag == \"def-list\":\n",
    "            for item in block.findall(\"./def-item\"):\n",
    "                term = _text(item.find(\"./term\"))\n",
    "                defs = item.findall(\"./def\")\n",
    "                if defs:\n",
    "                    for d in defs:\n",
    "                        t = _text(d)\n",
    "                        if t:\n",
    "                            lines.append(f\"{term + ': ' if term else ''}{t}\")\n",
    "                    lines.append(\"\")\n",
    "                else:\n",
    "                    t = _text(item)\n",
    "                    if t:\n",
    "                        lines.append(t)\n",
    "                        lines.append(\"\")\n",
    "        else:\n",
    "            t = _text(block)\n",
    "            if t:\n",
    "                lines.append(t)\n",
    "                lines.append(\"\")\n",
    "\n",
    "    def walk(node: ET.Element):\n",
    "        tag = local(node.tag)\n",
    "        if tag in SKIP_TAGS:\n",
    "            return\n",
    "\n",
    "        if tag == \"sec\":\n",
    "            title_el = node.find(\"./title\")\n",
    "            title = _text(title_el)\n",
    "            if title:\n",
    "                add_blank_line(lines)\n",
    "                lines.append(title.upper())\n",
    "                lines.append(\"\")\n",
    "\n",
    "            for child in node:\n",
    "                ctag = local(child.tag)\n",
    "                if ctag in SKIP_TAGS:\n",
    "                    continue\n",
    "                if ctag == \"p\":\n",
    "                    t = _text(child)\n",
    "                    if t:\n",
    "                        lines.append(t)\n",
    "                        lines.append(\"\")\n",
    "                elif ctag in {\"list\", \"def-list\", \"boxed-text\", \"disp-quote\", \"speech\", \"statement\"}:\n",
    "                    handle_block(child)\n",
    "                elif ctag == \"sec\":\n",
    "                    walk(child)\n",
    "            return\n",
    "\n",
    "        # Fora d'una sec, processa blocs comuns\n",
    "        if tag == \"p\":\n",
    "            t = _text(node)\n",
    "            if t:\n",
    "                lines.append(t)\n",
    "                lines.append(\"\")\n",
    "        elif tag in {\"list\", \"def-list\", \"boxed-text\", \"disp-quote\", \"speech\", \"statement\"}:\n",
    "            handle_block(node)\n",
    "        else:\n",
    "            for child in node:\n",
    "                walk(child)\n",
    "\n",
    "    if body is not None:\n",
    "        walk(body)\n",
    "        # Neteja finals en blanc\n",
    "        while lines and lines[-1] == \"\":\n",
    "            lines.pop()\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    # ----------- FALLBACK ABSTRACT -----------\n",
    "    if fallback_to_abstract:\n",
    "        abstracts: List[ET.Element] = []\n",
    "        for el in root.iter():\n",
    "            if local(el.tag) in {\"abstract\", \"trans-abstract\"}:\n",
    "                abstracts.append(el)\n",
    "\n",
    "        abs_lines: List[str] = []\n",
    "        for idx, abs_el in enumerate(abstracts, start=1):\n",
    "            # Títol de l'abstract si existeix\n",
    "            title_el = abs_el.find(\"./title\")\n",
    "            title = _text(title_el)\n",
    "            if title:\n",
    "                add_blank_line(abs_lines)\n",
    "                abs_lines.append(title.upper())\n",
    "                abs_lines.append(\"\")\n",
    "            elif len(abstracts) > 1:\n",
    "                add_blank_line(abs_lines)\n",
    "                abs_lines.append(f\"ABSTRACT {idx}\")\n",
    "                abs_lines.append(\"\")\n",
    "            else:\n",
    "                add_blank_line(abs_lines)\n",
    "                abs_lines.append(\"ABSTRACT\")\n",
    "                abs_lines.append(\"\")\n",
    "\n",
    "            # Paràgrafs dins de l'abstract (p, sec, llistes)\n",
    "            def walk_abs(n: ET.Element):\n",
    "                t = local(n.tag)\n",
    "                if t in SKIP_TAGS:\n",
    "                    return\n",
    "                if t == \"p\":\n",
    "                    txt = _text(n)\n",
    "                    if txt:\n",
    "                        abs_lines.append(txt)\n",
    "                        abs_lines.append(\"\")\n",
    "                elif t in {\"sec\", \"list\", \"def-list\", \"boxed-text\", \"disp-quote\", \"speech\", \"statement\"}:\n",
    "                    # reutilitzem la lògica general\n",
    "                    if t == \"sec\":\n",
    "                        st = _text(n.find(\"./title\"))\n",
    "                        if st:\n",
    "                            abs_lines.append(st.upper())\n",
    "                            abs_lines.append(\"\")\n",
    "                        for c in n:\n",
    "                            walk_abs(c)\n",
    "                    elif t == \"list\" or t == \"def-list\":\n",
    "                        # petita crida auxiliar\n",
    "                        before_len = len(lines)\n",
    "                        handle_block(n)  # escriu a 'lines', no a 'abs_lines', així que adaptem:\n",
    "                        # Movem el que s'ha escrit a 'lines' cap a 'abs_lines'\n",
    "                        pass\n",
    "                    else:\n",
    "                        txt = _text(n)\n",
    "                        if txt:\n",
    "                            abs_lines.append(txt)\n",
    "                            abs_lines.append(\"\")\n",
    "                else:\n",
    "                    for c in n:\n",
    "                        walk_abs(c)\n",
    "\n",
    "            # Implementació simple: iterem paràgrafs i sub-seccions principals\n",
    "            for child in list(abs_el):\n",
    "                if local(child.tag) == \"p\":\n",
    "                    txt = _text(child)\n",
    "                    if txt:\n",
    "                        abs_lines.append(txt)\n",
    "                        abs_lines.append(\"\")\n",
    "                elif local(child.tag) == \"sec\":\n",
    "                    st = _text(child.find(\"./title\"))\n",
    "                    if st:\n",
    "                        abs_lines.append(st.upper())\n",
    "                        abs_lines.append(\"\")\n",
    "                    for p in child.findall(\".//p\"):\n",
    "                        txt = _text(p)\n",
    "                        if txt:\n",
    "                            abs_lines.append(txt)\n",
    "                            abs_lines.append(\"\")\n",
    "                elif local(child.tag) in {\"list\", \"def-list\"}:\n",
    "                    # Tractem llista com paràgrafs plans\n",
    "                    tmp_before = len(lines)\n",
    "                    handle_block(child)  # escriu a 'lines'; capturem la sortida i la passem\n",
    "                    new_chunk = lines[tmp_before:]\n",
    "                    if new_chunk:\n",
    "                        abs_lines.extend(new_chunk)\n",
    "                        # netegem el buffer global 'lines' afegit accidentalment\n",
    "                        del lines[tmp_before:]\n",
    "\n",
    "        # Neteja\n",
    "        while abs_lines and abs_lines[-1] == \"\":\n",
    "            abs_lines.pop()\n",
    "        return \"\\n\".join(abs_lines)\n",
    "\n",
    "    # Si no hi ha body ni abstract (o fallback desactivat)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b2d23-0304-4080-ac0c-04dd62166f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"xml\"].progress_apply(get_plain_body_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beffd58-df87-4753-823b-45dfe3b3d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faecd095-f951-4a30-9341-3902947655fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"len\"] = df[\"text\"].apply(len)\n",
    "df[\"len\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015b443-486c-4596-87ac-6aa907f91053",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb99fa9-7ad3-463d-94ca-6cdc0d084519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"xml\", \"len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49831052-6d7b-4723-a0ca-ef95336e448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa-space-biology-knowledge-engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
